{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8sRM9AP9ngsL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Dataset,random_split\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import glob as gb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMuIDMOzoRIP",
        "outputId": "f4ebdf01-ad99-43bd-ddae-f4707a453c8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-0bOPHFpDNB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgTCXgowpiSO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "Vvb7LFFwqDMc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/lung-and-colon-cancer-histopathological-images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kwqx6QSxh9O",
        "outputId": "39366e3e-8000-46dd-b6d3-1a2b9e644020"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images\n",
            "License(s): CC-BY-SA-4.0\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip lung-and-colon-cancer-histopathological-images.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zd3OE7YLxnyW",
        "outputId": "cad017f7-d733-478e-cd52-442fa09d8300"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  lung-and-colon-cancer-histopathological-images.zip\n",
            "replace lung_colon_image_set/colon_image_sets/colon_aca/colonca1.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path=\"/content/lung_colon_image_set\"\n",
        "image_size=224\n",
        "epochs=100\n"
      ],
      "metadata": {
        "id": "dC7qRZ3Rx61w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,data_dir):\n",
        "    self.data_dir=data_dir\n",
        "    self.image_paths,self.labels,self.label_map,self.n_class=self.ReadDataset(self.data_dir)\n",
        "    self.transform=tv.transforms.Compose([\n",
        "        tv.transforms.Resize([image_size,image_size]),\n",
        "        tv.transforms.ToTensor()\n",
        "    ])\n",
        "  def ReadDataset(self,data_dir):\n",
        "    image_paths,labels=[],[]\n",
        "    label_map={}\n",
        "    idx=0\n",
        "    for folder in sorted(os.listdir(dataset_path)):\n",
        "      for i in sorted(os.listdir(os.path.join(dataset_path,folder))):\n",
        "        label_map[idx]=i\n",
        "        for path in os.listdir(dataset_path +'/'+ folder +'/'+ i):\n",
        "          files=gb.glob(pathname=str(dataset_path+\"/\"+folder+\"/\"+i+\"/\"+path ))\n",
        "          for file in files:\n",
        "            image_paths.append(file)\n",
        "            labels.append(idx)\n",
        "        idx+=1\n",
        "    n_class=len(label_map)\n",
        "    return np.array(image_paths) , np.array(labels) , label_map , n_class\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "  def __getitem__(self,index):\n",
        "    img=Image.open(self.image_paths[index])\n",
        "    img=self.transform(img)\n",
        "    label=torch.tensor(self.labels[index])\n",
        "    return img,label\n"
      ],
      "metadata": {
        "id": "SpznRHdvyK3W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWuie4lW22rB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=CustomDataset(dataset_path)"
      ],
      "metadata": {
        "id": "_fO7-yf42jey"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = ds.label_map\n",
        "N_CLASSES = ds.n_class\n",
        "label_map , N_CLASSES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c97NM3us2qvz",
        "outputId": "604b734c-c69c-4fb7-9c80-ed3e21340c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 'colon_aca', 1: 'colon_n', 2: 'lung_aca', 3: 'lung_n', 4: 'lung_scc'}, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * ds.__len__())\n",
        "val_size = int(0.2 * ds.__len__())\n"
      ],
      "metadata": {
        "id": "UcSonU3D3S1h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set,val_set=random_split(ds,[train_size,val_size])"
      ],
      "metadata": {
        "id": "MEaHLNPs3ydt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "train_ds = DataLoader(\n",
        "    train_set ,\n",
        "    batch_size = 64 ,\n",
        "    shuffle = True ,\n",
        "    pin_memory = True ,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "val_ds = DataLoader(\n",
        "    val_set ,\n",
        "    batch_size = 64 ,\n",
        "    shuffle = False ,\n",
        "    pin_memory = True ,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "Yqkp0YU438Uy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds),len(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUva-bO24Rer",
        "outputId": "73eb9ab8-1353-4028-bffa-7d6a4438e5fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(313, 79)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7LLqFBR8z4Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87vOKjlh8M68"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.linear import Linear\n",
        "model =nn.Sequential(\n",
        "    nn.Conv2d(3,32,3),\n",
        "     nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d((2,2)) ,\n",
        "    nn.Conv2d(32,64,3),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d((2,2)) ,\n",
        "    nn.Conv2d(64,128,3),\n",
        "      nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d((2,2)) ,\n",
        "     nn.Conv2d(128,256,3),\n",
        "        nn.BatchNorm2d(256),\n",
        "    nn.ReLU(),\n",
        "\n",
        "     nn.MaxPool2d((2,2)) ,\n",
        "    nn.AdaptiveAvgPool2d((1,1)),\n",
        "    nn.Flatten(),\n",
        "\n",
        "    nn.Linear(256,N_CLASSES)\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "gHRWujFg4e0D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=model.to(device)\n"
      ],
      "metadata": {
        "id": "YblBsjem70I2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJd2apIP-1zA",
        "outputId": "31100b71-796c-486e-98ab-72b5e4628a82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "ksOBkep3-2O6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model,input_size=(64,3,image_size,image_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNMl3ASB-6pa",
        "outputId": "a387d066-3bdf-4581-8c90-2040803a1d8c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential                               [64, 5]                   --\n",
              "├─Conv2d: 1-1                            [64, 32, 222, 222]        896\n",
              "├─BatchNorm2d: 1-2                       [64, 32, 222, 222]        64\n",
              "├─ReLU: 1-3                              [64, 32, 222, 222]        --\n",
              "├─MaxPool2d: 1-4                         [64, 32, 111, 111]        --\n",
              "├─Conv2d: 1-5                            [64, 64, 109, 109]        18,496\n",
              "├─BatchNorm2d: 1-6                       [64, 64, 109, 109]        128\n",
              "├─ReLU: 1-7                              [64, 64, 109, 109]        --\n",
              "├─MaxPool2d: 1-8                         [64, 64, 54, 54]          --\n",
              "├─Conv2d: 1-9                            [64, 128, 52, 52]         73,856\n",
              "├─BatchNorm2d: 1-10                      [64, 128, 52, 52]         256\n",
              "├─ReLU: 1-11                             [64, 128, 52, 52]         --\n",
              "├─MaxPool2d: 1-12                        [64, 128, 26, 26]         --\n",
              "├─Conv2d: 1-13                           [64, 256, 24, 24]         295,168\n",
              "├─BatchNorm2d: 1-14                      [64, 256, 24, 24]         512\n",
              "├─ReLU: 1-15                             [64, 256, 24, 24]         --\n",
              "├─MaxPool2d: 1-16                        [64, 256, 12, 12]         --\n",
              "├─AdaptiveAvgPool2d: 1-17                [64, 256, 1, 1]           --\n",
              "├─Flatten: 1-18                          [64, 256]                 --\n",
              "├─Linear: 1-19                           [64, 5]                   1,285\n",
              "==========================================================================================\n",
              "Total params: 390,661\n",
              "Trainable params: 390,661\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 40.55\n",
              "==========================================================================================\n",
              "Input size (MB): 38.54\n",
              "Forward/backward pass size (MB): 2898.99\n",
              "Params size (MB): 1.56\n",
              "Estimated Total Size (MB): 2939.09\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.003)"
      ],
      "metadata": {
        "id": "g75RNzQG_-Z4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for X, y in tqdm(train_ds, desc=f\"Epoch {epoch+1}\"):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optim.zero_grad()\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_ds)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw1bpXLTAlRe",
        "outputId": "38dcda77-f6a9-43bb-8f5c-27e339735033"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 313/313 [02:24<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Training Loss: 0.2501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 313/313 [02:21<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Training Loss: 0.1665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 313/313 [02:21<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100, Training Loss: 0.1331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 313/313 [02:19<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Training Loss: 0.0978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 313/313 [02:21<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100, Training Loss: 0.0784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 313/313 [02:20<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Training Loss: 0.0671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 313/313 [02:23<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Training Loss: 0.0587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 313/313 [02:21<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100, Training Loss: 0.0497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 313/313 [02:22<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100, Training Loss: 0.0468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 313/313 [02:23<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Training Loss: 0.0385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CAn2WeJBgeN",
        "outputId": "34eeb2ba-9b5d-4c8b-9b63-c9dcff4758b2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU()\n",
              "  (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): ReLU()\n",
              "  (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (10): ReLU()\n",
              "  (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (14): ReLU()\n",
              "  (15): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (16): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (17): Flatten(start_dim=1, end_dim=-1)\n",
              "  (18): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "        for X_val, y_val in val_ds:\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "            y_pred = model(X_val)\n",
        "            val_loss += loss_fn(y_pred, y_val).item()\n",
        "            correct += (y_pred.argmax(1) == y_val).sum().item()\n",
        "        val_loss /= len(val_ds)\n",
        "        val_acc = correct / len(val_set)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWiDvlYUC8lK",
        "outputId": "f6fddc41-54fb-4d56-c160-cd596e62d239"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0813, Validation Accuracy: 0.9652\n"
          ]
        }
      ]
    }
  ]
}